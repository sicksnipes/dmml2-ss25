{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Networks with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will build our first neural network using only `numpy` as library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work on the same dataset as last week and try to predict which digit is shown on the given pixel values. This time we load the dataset directly from sklearn using 28x28 pixels to show the digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n\u001b[32m      2\u001b[39m X, y = fetch_openml(\u001b[33m'\u001b[39m\u001b[33mmnist_784\u001b[39m\u001b[33m'\u001b[39m, version=\u001b[32m1\u001b[39m, return_X_y=\u001b[38;5;28;01mTrue\u001b[39;00m, data_home=\u001b[33m\"\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m\"\u001b[39m, cache=\u001b[38;5;28;01mTrue\u001b[39;00m, parser=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home=\"./data\", cache=True, parser='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know already from last time how the data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0        0  ...         0         0         0         0         0         0   \n",
       "1        0  ...         0         0         0         0         0         0   \n",
       "2        0  ...         0         0         0         0         0         0   \n",
       "3        0  ...         0         0         0         0         0         0   \n",
       "4        0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the following histogram we see that the pixel values are between `0` and `255`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.iloc[0].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is a number between 0-9 representing the digit shown on the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    0\n",
       "2    4\n",
       "Name: class, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the label is given as a digit. However, to calculate the loss function of the neural network, we need the label as a one-hot-encoded version, in which the true digit is encoded as `1` and the rest as `0`.\n",
    "\n",
    "For instance:\n",
    "- `3` -> `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`\n",
    "- `9` -> `[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]`\n",
    "\n",
    "This is done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_categorical = pd.get_dummies(y).astype('float32').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first five lines to check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_categorical[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we scale the data in the range [0,1] and divide it into train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_scaled = (X/255).astype('float32').values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the following structure of a neural network with two hidden layers:\n",
    "- Input layer of size 784 with sigmoid activation\n",
    "- First hidden layer of size 128 with sigmoid activation\n",
    "- Second hidden layer of size 64 with sigmoid activation\n",
    "- Output layer of size 10 with softmax activation\n",
    "\n",
    "A skeleton code for this network is given in the following class. Your first task is to complete the method `forward_pass` to calculate the forward pass on __one__ data point. Below this cell you can find a test to check whether your implementation is correct. Also see the hint below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDeepNeuralNetwork\u001b[39;00m():\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# do not touch this method\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m         \u001b[38;5;66;03m# initialize weights randomly\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class DeepNeuralNetwork():\n",
    "    \n",
    "    # do not touch this method\n",
    "    def __init__(self):\n",
    "        \n",
    "        # initialize weights randomly\n",
    "        np.random.seed(0)\n",
    "        self.w1 = np.random.randn(128, 784)\n",
    "        self.w2 = np.random.randn(64, 128)\n",
    "        self.w3 = np.random.randn(10, 64)\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        z1 = np.dot(self.w1, x_train)\n",
    "        a1 = 1 / (1 + np.exp(-z1))\n",
    "        z2 = np.dot(self.w2, a1)\n",
    "        a2 = 1 / (1 + np.exp(-z2))\n",
    "        z3 = np.dot(self.w3, a2)\n",
    "        exps = np.exp(z3 - np.max(z3))\n",
    "        a3 = exps / np.sum(exps)\n",
    "        \n",
    "        # we need to remember all values for the gradient calculation, don't touch this\n",
    "        self.fwdpass = [x_train, z1, a1, z2, a2, z3, a3]\n",
    "        \n",
    "        return a3\n",
    "    \n",
    "    # do not touch this method\n",
    "    def get_gradients(self, y, y_hat):\n",
    "        # restore values from foward pass\n",
    "        a0, z1, a1, z2, a2, z3, a3 = self.fwdpass\n",
    "        \n",
    "        # Calculate W3 update\n",
    "        exps = np.exp(z3 - z3.max())\n",
    "        softmax_derivative = exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        error = 2 * (y_hat - y) / y_hat.shape[0] * softmax_derivative\n",
    "        gradient_w3 = np.outer(error, a2)\n",
    "\n",
    "        # Calculate W2 update\n",
    "        sigmoid_derivative = (np.exp(-z2))/((np.exp(-z2)+1)**2)\n",
    "        error = np.dot(self.w3.T, error) * sigmoid_derivative\n",
    "        gradient_w2 = np.outer(error, a1)\n",
    "\n",
    "        # Calculate W1 update\n",
    "        sigmoid_derivative = (np.exp(-z1))/((np.exp(-z1)+1)**2)\n",
    "        error = np.dot(self.w2.T, error) * sigmoid_derivative\n",
    "        gradient_w1 = np.outer(error, a0)\n",
    "\n",
    "        return [gradient_w1, gradient_w2, gradient_w3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: To calculate the ouput of a layer you can use numpys matrix operations, as we have seen it in the lecture slides.\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([[2,2,2],[1,1,1]])\n",
    "print(w)\n",
    "print(w.shape)\n",
    "x = np.array([3, 4, 5])\n",
    "print(x.shape)\n",
    "\n",
    "z = np.dot(w, x)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for task 1:\n",
    "dnn = DeepNeuralNetwork()\n",
    "\n",
    "# the network outputs a probability for every neuron in the last layer\n",
    "y_hat = dnn.forward_pass(X_train[0])\n",
    "print(\"The output of the last layer looks like this:\\n\", y_hat)\n",
    "\n",
    "# to check if the network works correctly, check if the following condition is True\n",
    "abs(y_hat[8] - 0.946) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement  the training procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start training the network by implementing the training procedure. We train the network for 10 epochs as shown in the code below.\n",
    "In each epoch we go over every data point `x` in `X_train` and:\n",
    "1. Calculate a forward pass on `x` and save it as `y_hat`. Use the `forward_pass` method that you implemeneted in the previous task.\n",
    "2. Calculate the gradients for the weight in w1, w2 and w3 using the `get_gradient` function of the network\n",
    "3. Update the weights `w1`, `w2` and `w3` of the network by moving into the negative direction of the gradient multiplied with the `learning_rate`\n",
    "4. Bonus: Calculate the cross-entropy-loss after each epoch and plot it in relation to the epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DeepNeuralNetwork()\n",
    "\n",
    "no_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "for iteration in range(no_epochs):\n",
    "    # calc forward pass on x, save as y_hat use forward_pass method\n",
    "    y_hat = dnn.forward_pass(X_train[0])\n",
    "\n",
    "    # calc gradients for w1, w2, w3 use get_gradients method\n",
    "    gradients = dnn.get_gradients(y_train[0], y_hat)\n",
    "\n",
    "    # update weights w1, w2, w3 using the gradients and learning rate\n",
    "    dnn.w1 -= learning_rate * gradients[0]\n",
    "    dnn.w2 -= learning_rate * gradients[1]\n",
    "    dnn.w3 -= learning_rate * gradients[2]\n",
    "\n",
    "    # calc cross entropy loss after each epoch and plot in relation to epoch\n",
    "    loss = -np.sum(y_train[0] * np.log(y_hat))\n",
    "    losses.append(loss)\n",
    "    print(\"Epoch: \", iteration, \"Loss: \", loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Predict on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the network is trained, we can use it to predict on the test data.\n",
    "\n",
    "Task: \n",
    "- Iterate over the test data and use the trained network the predict on every test data point.\n",
    "- Identify the index of the neuron which returned the highest probability.\n",
    "- Compare this value to the true label in the test data.\n",
    "- Compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the test data and use the trained network the predict on every test data point.\n",
    "correct_predictions = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    y_hat = dnn.forward_pass(X_test[i])\n",
    "    predicted_label = np.argmax(y_hat)\n",
    "    true_label = np.argmax(y_test[i])\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(X_test)\n",
    "print(\"Accuracy on test data:\", accuracy)\n",
    "\n",
    "# Identify the index of the neuron which returned the highest probability.\n",
    "highest_probability_index = np.argmax(y_hat)\n",
    "print(\"Index of the neuron with the highest probability:\", highest_probability_index)\n",
    "\n",
    "# Compare this value to the true label in the test data.\n",
    "print(\"True label:\", true_label)\n",
    "print(\"Predicted label:\", predicted_label)\n",
    "\n",
    "# Compute the accuracy.\n",
    "accuracy = correct_predictions / len(X_test)\n",
    "print(\"Accuracy on test data:\", accuracy)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task:\n",
    "- Remove the first hidden layer. Train the network and check the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
